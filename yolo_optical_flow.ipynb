{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdCounter:\n",
    "    def _init_(self, model_path=None, person_class_id=0):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device for YOLO model: {self.device}\")\n",
    "\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            try:\n",
    "                self.model = YOLO(model_path)\n",
    "                print(f\"YOLO model loaded successfully from {model_path}\")\n",
    "                if \"yolov11\" in model_path.lower():\n",
    "                    print(\"Attempting to use YOLOv11.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading YOLO model from {model_path}: {e}. Please check the path and file format (e.g., .pt).\")\n",
    "                print(\"Attempting to load default YOLOv8n model as a fallback...\")\n",
    "                self.model = YOLO('yolov8n.pt') \n",
    "                print(\"Default YOLOv8n model loaded.\")\n",
    "        else:\n",
    "            print(f\"Warning: YOLO model not found at {model_path}. Loading default YOLOv8n model as a fallback.\")\n",
    "            self.model = YOLO('yolov8n.pt') \n",
    "            print(\"Default YOLOv8n model loaded.\")\n",
    "        \n",
    "        self.person_class_id = person_class_id \n",
    "        print(f\"Configured to count objects with class ID: {self.person_class_id} (typically 'person' in COCO).\")\n",
    "\n",
    "    def predict(self, image_np):\n",
    "        results = self.model.predict(image_np, verbose=False) \n",
    "\n",
    "        pred_count = 0\n",
    "        boxes_with_conf = []\n",
    "\n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                class_id = int(box.cls) \n",
    "                if class_id == self.person_class_id: \n",
    "                    pred_count += 1\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                    conf = float(box.conf)\n",
    "                    boxes_with_conf.append({'box': (x1, y1, x2, y2), 'confidence': conf})\n",
    "        \n",
    "        return pred_count, boxes_with_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bcef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video_inference(model_path, video_path, output_video_path, person_class_id=0):\n",
    "\n",
    "    print(f\"Attempting to load YOLO model from: {model_path}\")\n",
    "    counter = CrowdCounter(model_path=model_path, person_class_id=person_class_id)\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}. Please check the path and file format.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(f\"Processing video: {video_path} ({frame_width}x{frame_height} @ {fps:.2f} FPS)\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        print(f\"Error: Could not open video writer for {output_video_path}. Check file path, permissions, and codec support.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    print(f\"Saving output video to: {output_video_path}\")\n",
    "\n",
    "    prev_gray = None \n",
    "    hsv = None \n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read() \n",
    "        if not ret:\n",
    "            print(\"End of video stream or error reading frame. Exiting.\")\n",
    "            break\n",
    "\n",
    "        pred_count, detections = counter.predict(frame)\n",
    "\n",
    "        current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_gray is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "\n",
    "            if hsv is None:\n",
    "                hsv = np.zeros_like(frame)\n",
    "                hsv[...,1] = 255 \n",
    "\n",
    "            hsv[...,0] = ang * 180 / np.pi / 2 \n",
    "            hsv[...,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) \n",
    "\n",
    "            rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            frame = cv2.addWeighted(frame, 1, rgb_flow, 0.5, 0) \n",
    "        else:\n",
    "            print(\"  Skipping optical flow for the first frame (no previous frame to compare).\")\n",
    "\n",
    "        prev_gray = current_gray\n",
    "\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det['box']\n",
    "            confidence = det['confidence']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "            cv2.putText(frame, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        count_text = f\"Count: {pred_count}\"\n",
    "        cv2.putText(frame, count_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('YOLO Crowd Counting with Optical Flow', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\" 'q' pressed. Exiting video stream.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release() \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video processing completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _name_ == '_main_':\n",
    "\n",
    "    your_yolo_model_path = \"C:\\\\Users\\\\Odwitiyo\\\\Downloads\\\\yolov8m.pt\"  \n",
    "    your_input_video_path = \"C:\\\\Users\\\\Odwitiyo\\\\Downloads\\\\crowd_test_data\\\\1.mp4\" \n",
    "    your_output_video_path = \"yolo_crowd_counting_output_with_flow.mp4\" \n",
    "\n",
    "    yolo_person_class_id = 0 \n",
    "    run_video_inference(your_yolo_model_path, \n",
    "                        your_input_video_path,\n",
    "                        your_output_video_path, \n",
    "                        yolo_person_class_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
